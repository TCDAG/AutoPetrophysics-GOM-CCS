{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P Global - Well Logs \n",
    "### Misael M. Morales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ccs_sand_wells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv('Data/UT dir surveys/427064023000_DIRSUR_NAD27(USFEET)US-SPC27-EXACT(TX-27SC).TXT',skiprows=3, sep='\\s+')\n",
    "#survey = pd.read_csv('Data/UT dir surveys/177004037400_DIRSUR_NAD27(USFEET)US-SPC27-EXACT(LA-27S).TXT',skiprows=3, sep='\\s+')\n",
    "plot_survey(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "k = 0\n",
    "for root, dirs, files in os.walk('Data/UT Export 9-19'):\n",
    "    for f in files:\n",
    "        fname = os.path.join(root, f)\n",
    "        df = lasio.read(fname).df()\n",
    "        headers[k] = df.columns\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = '17700004060000'\n",
    "well_log = lasio.read('Data/UT Export 9-19/{}.las'.format(well_name))\n",
    "well_name, well_field = well_log.header['Well']['WELL'].value, well_log.header['Well']['FLD'].value\n",
    "print(well_log.curvesdict.keys())\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(10, 8), sharey=True)\n",
    "fig.suptitle('{} | {}'.format(well_field, well_name), weight='bold')\n",
    "ax1, ax2, ax3, ax4, ax5 = axs.flatten()\n",
    "\n",
    "ax11, ax12 = ax1.twiny(), ax1.twiny()\n",
    "plot_curve(ax12, well_log, 'CALI', 0.1, 100, color='k', fill=True)\n",
    "plot_curve(ax1, well_log, 'GR', 0, 120, color='olive', pad=1.08)\n",
    "plot_curve(ax11, well_log, 'GR_NORM', 0, 120, color='darkgreen', pad=1.16)\n",
    "\n",
    "ax21 = ax2.twiny()\n",
    "plot_curve(ax2, well_log, 'SP', -120, 20, color='magenta')\n",
    "plot_curve(ax21, well_log, 'SP_NORM', -120, 20, color='darkmagenta', pad=1.08)\n",
    "\n",
    "ax31 = ax3.twiny()\n",
    "plot_curve(ax3, well_log, 'VSH_GR', -0.05, 1.05, color='green')\n",
    "plot_curve(ax31, well_log, 'VSH_SP', -0.05, 1.05, color='purple', alpha=0.7, pad=1.08)\n",
    "\n",
    "ax41 = ax4.twiny()\n",
    "plot_curve(ax4, well_log, 'ILD', 0.2, 20, color='r', semilog=True)\n",
    "plot_curve(ax41, well_log, 'ASN', 0.2, 20, color='b', semilog=True, pad=1.08)\n",
    "\n",
    "ax51, ax52 = ax5.twiny(), ax5.twiny()\n",
    "plot_curve(ax5, well_log, 'RHOB', 1.65, 2.65, color='tab:red')\n",
    "plot_curve(ax51, well_log, 'DRHO', -0.5, 0.5, color='k', linestyle='--', pad=1.08)\n",
    "plot_curve(ax52, well_log, 'DT', 50, 180, color='tab:blue', pad=1.16)\n",
    "\n",
    "ax1.set_ylabel('DEPTH [ft]', weight='bold')\n",
    "plt.gca().invert_yaxis(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "pd.plotting.autocorrelation_plot(well_log['SP'])\n",
    "plt.title('Autocorrelation of SP')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(well_log['SP'], order=(5,1,0))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "\n",
    "mu, std = stats.norm.fit(model_fit.resid)\n",
    "x = np.linspace(-20, 20, 500)\n",
    "p = stats.norm.pdf(x, mu ,std)\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "ax.plot(model_fit.resid, c='tab:blue', label='Residuals')\n",
    "ax2.plot(p,x, c='tab:red', linewidth=3, label='PDF')\n",
    "ax2.set_xticks([])\n",
    "\n",
    "plt.title('ARIMA MODEL | Residuals', weight='bold')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# SP BASELINE CORRECTION\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRELOAD\n",
    "logs = np.load('Data/log_data.npy')\n",
    "print(logs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_list = {}\n",
    "files = os.listdir('Data/UT Export 9-19/')\n",
    "k = 0\n",
    "for file in tqdm(files, desc='Processing Files', unit='file'):\n",
    "    log = lasio.read('Data/UT Export 9-19/{}'.format(file))\n",
    "    if 'SP' in log.curvesdict.keys() and 'SP_NORM' in log.curvesdict.keys():\n",
    "        logs_list[k] = pd.DataFrame({'DEPT': log['DEPT'], 'SP': log['SP'], 'SP_NORM': log['SP_NORM']})\n",
    "        k += 1\n",
    "\n",
    "logs = np.zeros((len(logs_list),44055,3))\n",
    "for i in range(len(logs_list)):\n",
    "    logs[i,logs_list[i].index,:] = logs_list[i].values\n",
    "logs = np.where(logs==0, np.nan, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 10, figsize=(20, 12), sharey=True)\n",
    "k = 0\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        axs[i,j].plot(logs[k,:,1], logs[k,:,0], c='tab:purple', label='SP')\n",
    "        axs[i,j].plot(logs[k,:,2], logs[k,:,0], c='darkmagenta', label='SP_NORM')\n",
    "        axs[i,j].set_title(os.listdir('Data/UT Export 9-19/')[k].split('.')[0], weight='bold')\n",
    "        axs[i,0].set_ylabel('DEPTH [ft]', weight='bold')\n",
    "        axs[-1,j].set_xlabel('SP [mV]', weight='bold')\n",
    "        axs[i,j].set_xlim(-200, 50)\n",
    "        axs[i,j].grid(True, which='both')\n",
    "        k += 1\n",
    "#axs[-1,-1].legend(facecolor='wheat', edgecolor='k')\n",
    "axs[0,0].invert_yaxis()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_clean = np.nan_to_num(logs, nan=0)\n",
    "print(logs_clean.shape)\n",
    "\n",
    "X_data = np.expand_dims(logs_clean[:,:,:2],-1)\n",
    "y_data = np.expand_dims(np.expand_dims(logs_clean[:,:,-1],-1),-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.227)\n",
    "\n",
    "print('X_train: {} | y_train: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test:  {}  | y_test:  {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 10, figsize=(20, 12), sharey=True)\n",
    "k = 0\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        axs[i,j].plot(logs_clean[k,:,1], logs_clean[k,:,0], c='tab:purple', label='SP')\n",
    "        axs[i,j].plot(logs_clean[k,:,2], logs_clean[k,:,0], c='darkmagenta', label='SP_NORM')\n",
    "        axs[i,j].set_title(os.listdir('Data/UT Export 9-19/')[k].split('.')[0], weight='bold')\n",
    "        axs[i,0].set_ylabel('DEPTH [ft]', weight='bold')\n",
    "        axs[-1,j].set_xlabel('SP [mV]', weight='bold')\n",
    "        axs[i,j].set_xlim(-200, 50)\n",
    "        axs[i,j].grid(True, which='both')\n",
    "        k += 1\n",
    "#axs[-1,-1].legend(facecolor='wheat', edgecolor='k')\n",
    "axs[0,0].invert_yaxis()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, LSTM, ConvLSTM1D, Conv1D, Conv1DTranspose, BatchNormalization, LeakyReLU, ReLU, MaxPooling1D, UpSampling1D\n",
    "from keras.layers import Concatenate, Add, Reshape, Flatten, Dense, Dropout, ZeroPadding1D, Cropping1D, GlobalAveragePooling1D\n",
    "\n",
    "def make_nn():\n",
    "    K.clear_session()\n",
    "    def enc_layer(inp, units):\n",
    "        _ = Conv1D(units, 15, padding='same')(inp)\n",
    "        _ = BatchNormalization()(_)\n",
    "        _ = ReLU()(_)\n",
    "        _ = MaxPooling1D(2)(_)\n",
    "        return _\n",
    "    \n",
    "    def dec_layer(inp, units):\n",
    "        _ = Conv1D(units, 15, padding='same')(inp)\n",
    "        _ = BatchNormalization()(_)\n",
    "        _ = ReLU()(_)\n",
    "        _ = UpSampling1D(2)(_)\n",
    "        return _\n",
    "    \n",
    "    inputs = Input(shape=(44055,2))\n",
    "\n",
    "    x1 = enc_layer(inputs, 16)\n",
    "    x2 = enc_layer(x1, 64)\n",
    "    x3 = enc_layer(x2, 128)\n",
    "\n",
    "    y3 = dec_layer(x3, 64)\n",
    "    y2 = dec_layer(y3, 16)\n",
    "    y1 = dec_layer(y2, 4)\n",
    "\n",
    "    _ = ZeroPadding1D((4,3))(y1)\n",
    "    _ = Conv1D(1, 15, padding='same')(_)\n",
    "\n",
    "    return Model(inputs, _)\n",
    "\n",
    "model = make_nn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['mse'])\n",
    "fit = model.fit(X_train, y_train, \n",
    "                epochs           = 100,\n",
    "                batch_size       = 30,\n",
    "                validation_split = 0.25,\n",
    "                shuffle          = True,\n",
    "                verbose          = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train).squeeze().astype('float32')\n",
    "y_test_pred  = model.predict(X_test).squeeze().astype('float32')\n",
    "print('y_train_pred: {} | y_test_pred: {}'.format(y_train_pred.shape, y_test_pred.shape))\n",
    "\n",
    "train_mse = mean_squared_error(y_train.squeeze().astype('float32'), y_train_pred)\n",
    "test_mse  = mean_squared_error(y_test.squeeze().astype('float32'), y_test_pred)\n",
    "print('Train MSE: {:.4f} | Test MSE: {:.4f}'.format(train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.squeeze(), X_test.squeeze(), y_train.squeeze(), y_test.squeeze()\n",
    "print('X_train: {} | y_train: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test:  {}  | y_test:  {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 3, 8\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(20, 12))\n",
    "k, mult = 0, 5\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "\n",
    "        mask = ~np.isnan(X_train[k,:,0])\n",
    "        index = X_train[k,:,0][mask]\n",
    "        x  = X_train[k,:,1][mask]\n",
    "        y  = y_train[k][mask]\n",
    "        yh = y_train_pred[k][mask]\n",
    "\n",
    "        axs[i,j].plot(x, index, c='tab:purple', label='SP')\n",
    "        axs[i,j].plot(y, index, c='darkmagenta', label='True Corr.')\n",
    "        axs[i,j].plot(yh, index, c='k', label='Pred Corr.')\n",
    "\n",
    "        axs[i,0].set_ylabel('DEPTH [ft]', weight='bold')\n",
    "        axs[-1,j].set_xlabel('SP [mV]', weight='bold')\n",
    "        axs[i,j].set_xlim(-200, 50)\n",
    "        axs[i,j].grid(True, which='both')\n",
    "        axs[i,j].invert_yaxis()\n",
    "        k += 1*mult\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
