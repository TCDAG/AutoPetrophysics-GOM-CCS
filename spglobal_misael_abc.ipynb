{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P Global - AUTOMATIC BASELINE CORRECTION\n",
    "### Misael M. Morales, Carlos Torres-Verdin, and Michael Pyrcz, UT-Austin; Murray Christie, Vladimir Rabinovich, S&P Global\n",
    "#### 2024, Digital Reservoir Characterization Technology (DiReCT)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_baseline_correction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# LOG ANALYSIS\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the LogAnalysis class\n",
    "spl = SPLogAnalysis()\n",
    "spl.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### WARNING: this takes a long time to run, only do it if you need to\n",
    "# headers = spl.read_all_headers()\n",
    "\n",
    "# Plot the spatial distribution of wells and the selected property\n",
    "spl.plot_ccs_sand_wells(figsize=(8,3), value='POROSITY', cmap='jet')\n",
    "\n",
    "# Plot a well deviation survey for a given well\n",
    "spl.plot_survey(figsize=(10,3), fname='427064023000_DIRSUR_NAD27(USFEET)US-SPC27-EXACT(TX-27SC).TXT')\n",
    "\n",
    "# Plot the full well log with multiple tracks\n",
    "# also plots the autocorrelation plot and ARIMA model curve\n",
    "spl.plot_well(figsize=(10,8), well_name='17700004060000', curve='SP', order=(5,1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# SP BASELINE CORRECTION\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanstiate the BaselineCorrection class\n",
    "blc = BaselineCorrection()\n",
    "blc.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .LAS files from scratch (preload=False). \n",
    "# This means you don't have a pre-existing .npy file with the pre-loaded data.\n",
    "# The .LAS files are in your 'data' folder, and this will output a log_data.npy file with the preprocessed logs.\n",
    "blc.load_logs(preload      = True,                  #change me to False if you don't have a pre-existing .npy file \n",
    "              preload_file = 'Data/log_data.npy',   #change me (if preload_file is not 'Data/log_data.npy')\n",
    "              folder       = 'Data/UT Export 9-19', #change me (if preload folder is not 'Data/UT Export 9-19' and preload=False)\n",
    "              save_file    = 'Data/log_data.npy',   #change me to save your preprocessed raw logs [.LAS -> .npy]\n",
    "              showfig      = True,\n",
    "              )\n",
    "\n",
    "# Process the numpy logs. \n",
    "# This will scale the data according to the chosen scaler, and perform random train_test_split\n",
    "# scaler can be either ('standard', 'minmax', or 'none')\n",
    "blc.scale_and_random_split(scaler='standard', \n",
    "                           test_size=0.227, \n",
    "                           showfig=True,\n",
    "                          )\n",
    "\n",
    "# Make the baseline correction NN model.\n",
    "# If pretrained:\n",
    "#    - the model will be loaded from the file pretrained='baseline_correction_model.keras'\n",
    "# Else:\n",
    "#    - we construct a model from scratch based on the auxiliary functions in the class\n",
    "#    - and train the model on the training data\n",
    "blc.make_model(pretrained   = 'baseline_correction_model.keras', #change me to None to train from scratch\n",
    "               show_summary = False, \n",
    "               kernel_size  = 15, \n",
    "               dropout      = 0.2,\n",
    "               depths       = [16,32,64], \n",
    "               optimizer    = 'adam',\n",
    "               lr           = 1e-3,\n",
    "               loss         = 'mse',\n",
    "               metrics      = ['mse'],\n",
    "               epochs       = 100,\n",
    "               batch_size   = 30,\n",
    "               valid_split  = 0.25,\n",
    "               verbose      = True,\n",
    "               figsize      = (10,5),\n",
    "               )\n",
    "\n",
    "# Make predictions on the test data and visualize results\n",
    "blc.make_predictions(showfig=True, xlim=(-5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Transfer Learning Baseline Correction\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the TransferLearning-BaselineCorrection class\n",
    "tlc = TransferLearning()\n",
    "tlc.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SP* and Csh estimation\n",
    "# Using the pre-trained model from the BaselineCorrection class, we can predict the baseline-correct SP log\n",
    "# and the Csh for every well log in the data folder. The .LAS files are updated with the 2 new curves, and \n",
    "# saved in a 'postprocess' folder.\n",
    "tlc.make_transfer_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results of the SP baseline correction and Csh estimation for a given well\n",
    "tlc.plot_transfer_results(filenum = 309,\n",
    "                          figsize = (10,8),\n",
    "                          showfig = True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
